{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a0306114",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import missingness_generation\n",
    "#from src.cleaning import datacleaning\n",
    "#from src import missingness_generation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import aif360\n",
    "from aif360.algorithms.preprocessing.reweighing import Reweighing\n",
    "from aif360.algorithms.postprocessing import CalibratedEqOddsPostprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from aif360.sklearn.metrics import statistical_parity_difference\n",
    "from aif360.sklearn.metrics import average_odds_difference\n",
    "from aif360.sklearn.metrics import equal_opportunity_difference\n",
    "from aif360.algorithms.inprocessing.adversarial_debiasing import AdversarialDebiasing\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f9be16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned = datacleaning.cleaning(os.path.join(os.path.dirname(\n",
    "#     os.path.realpath('run.py')) + '/data/test.csv')).iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0aad6d8d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/gykim/MissingnessFairnessAnalysis/data/allegations.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_250/3336957998.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m data = pd.read_csv(os.path.join(os.path.dirname(\n\u001b[0m\u001b[1;32m      2\u001b[0m     os.path.realpath('run.py')) + '/data/allegations.csv')).iloc[:,1:]\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 932\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1214\u001b[0m             \u001b[0;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[1;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/gykim/MissingnessFairnessAnalysis/data/allegations.csv'"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(os.path.join(os.path.dirname(\n",
    "    os.path.realpath('run.py')) + '/data/allegations.csv')).iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "395b33d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('allegations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b23088bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['complaint_id', 'complainant_ethnicity', 'complainant_gender', 'complainant_age_incident',\n",
    "       'allegation', 'contact_reason', 'Substantiated']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1eaff1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.rename(columns = {'Substantiated': 'substantiated'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "add91a9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "complaint_id                   0\n",
       "complainant_ethnicity       5505\n",
       "complainant_gender          4195\n",
       "complainant_age_incident    4829\n",
       "allegation                     1\n",
       "contact_reason               199\n",
       "substantiated                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "069dbf3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>complaint_id</th>\n",
       "      <th>complainant_ethnicity</th>\n",
       "      <th>complainant_gender</th>\n",
       "      <th>complainant_age_incident</th>\n",
       "      <th>allegation</th>\n",
       "      <th>contact_reason</th>\n",
       "      <th>substantiated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42835</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>Failure to provide RTKA card</td>\n",
       "      <td>Report-domestic dispute</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24601</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Action</td>\n",
       "      <td>Moving violation</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24601</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Race</td>\n",
       "      <td>Moving violation</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26146</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Question</td>\n",
       "      <td>PD suspected C/V of violation/crime - street</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40253</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Physical force</td>\n",
       "      <td>Report-dispute</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   complaint_id complainant_ethnicity complainant_gender  \\\n",
       "0         42835                 Black             Female   \n",
       "1         24601                 Black               Male   \n",
       "2         24601                 Black               Male   \n",
       "3         26146                 Black               Male   \n",
       "4         40253                   NaN                NaN   \n",
       "\n",
       "   complainant_age_incident                    allegation  \\\n",
       "0                      38.0  Failure to provide RTKA card   \n",
       "1                      26.0                        Action   \n",
       "2                      26.0                          Race   \n",
       "3                      45.0                      Question   \n",
       "4                      16.0                Physical force   \n",
       "\n",
       "                                 contact_reason  substantiated  \n",
       "0                       Report-domestic dispute           True  \n",
       "1                              Moving violation           True  \n",
       "2                              Moving violation           True  \n",
       "3  PD suspected C/V of violation/crime - street           True  \n",
       "4                                Report-dispute           True  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b9a145",
   "metadata": {},
   "source": [
    "We want the attribute with missingness to have around the same proportion of missingness for each type. This is because we don't want the amount of missingness to be a confounding factor in our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c9003b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gykim/MissingnessFairnessAnalysis/missingness_generation.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[column].iloc[i] = np.nan\n"
     ]
    }
   ],
   "source": [
    "mcar = data.copy()\n",
    "mcar = missingness_generation.mcar(mcar, 'substantiated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e9551b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19866298938785298"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcar['substantiated'].isna().sum() / mcar.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9665fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcar = mcar.dropna(subset = 'substantiated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d37671df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gykim/MissingnessFairnessAnalysis/missingness_generation.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[miss_column].iloc[i] = np.nan\n"
     ]
    }
   ],
   "source": [
    "mar = data.copy()\n",
    "mar = missingness_generation.mar(mar, 'substantiated', 'complainant_ethnicity', 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78d7a05c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12042088854247857"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mar['substantiated'].isna().sum() / mar.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "550eec64",
   "metadata": {},
   "outputs": [],
   "source": [
    "mar = mar.dropna(subset = 'substantiated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e0c7eac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gykim/MissingnessFairnessAnalysis/missingness_generation.py:112: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[column].iloc[i] = np.nan\n"
     ]
    }
   ],
   "source": [
    "nmar = data.copy()\n",
    "nmar = missingness_generation.nmar(nmar, 'substantiated', 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "91e6f66b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2007914143533785"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmar['substantiated'].isna().sum() / nmar.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e30cfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmar = nmar.dropna(subset = 'substantiated')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c14eb6",
   "metadata": {},
   "source": [
    "Now we will \"handle\" the missingness by dropping missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d614b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e5b733",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f3aa438",
   "metadata": {},
   "source": [
    "## Applying Fairness Notions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4319bf06",
   "metadata": {},
   "source": [
    "Fairness Notion with No Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f89709f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cec495cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "nypd = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3dacd466",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_250/1225942194.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nypd['complainant_age_incident'] = nypd['complainant_age_incident'].astype(str)\n"
     ]
    }
   ],
   "source": [
    "nypd['complainant_age_incident'] = nypd['complainant_age_incident'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d6ff9dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "complaint_id                 int64\n",
       "complainant_ethnicity       object\n",
       "complainant_gender          object\n",
       "complainant_age_incident    object\n",
       "allegation                  object\n",
       "contact_reason              object\n",
       "substantiated                 bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nypd.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c86ae89",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(nypd, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "776e6a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = [\"complainant_ethnicity\", \"complainant_gender\", \"complainant_age_incident\", \"allegation\", \"contact_reason\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ac9d7d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(train, test, cats):\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "    \n",
    "    traincat_df = train[cats]\n",
    "    # OHE train categorical\n",
    "    train_ohe = ohe.fit_transform(traincat_df)\n",
    "    # concat non-cat train features\n",
    "    train_len = train.shape[0]\n",
    "\n",
    "    train_num_feats = np.concatenate(\n",
    "        [np.reshape(train.complainant_age_incident.values, (train_len, 1))\n",
    "        ], axis = 1\n",
    "    )\n",
    "    \n",
    "    # concatenate train OHE features with non-cat features\n",
    "    train_feats = pd.DataFrame(np.concatenate([train_ohe.todense(), train_num_feats], axis = 1))\n",
    "    train_feats['complainant_ethnicity'] = (train['complainant_ethnicity'] == \"White\").tolist()\n",
    "    train_feats['complainant_gender'] = (train['complainant_gender'] == \"Male\").tolist()\n",
    "    y_train = train.substantiated.values.astype('int')\n",
    "    \n",
    "    mod = LogisticRegression(C = 1.0, class_weight='balanced')\n",
    "    mod.fit(train_feats, y_train)\n",
    "    \n",
    "    testcat_df = test[cats]\n",
    "    # OHE train categorical\n",
    "    test_ohe = ohe.transform(testcat_df)\n",
    "    # concat non-cat train features\n",
    "    test_len = test.shape[0]\n",
    "\n",
    "    test_num_feats = np.concatenate(\n",
    "        [np.reshape(test.complainant_age_incident.values, (test_len, 1)),\n",
    "        ], axis = 1\n",
    "    )\n",
    "        \n",
    "    # concatenate test OHE features with non-cat features\n",
    "    test_feats = pd.DataFrame(np.concatenate([test_ohe.todense(), test_num_feats], axis = 1))\n",
    "    test_feats['complainant_ethnicity'] = (test['complainant_ethnicity'] == \"White\").tolist()\n",
    "    test_feats['complainant_gender'] = (test['complainant_gender'] == \"Male\").tolist()\n",
    "    y_test = test.substantiated.values.astype('int')\n",
    "    \n",
    "    pred = mod.predict(test_feats)\n",
    "    \n",
    "    parity = statistical_parity_difference(pd.Series(y_test), pd.Series(pred))\n",
    "    odds = average_odds_difference(pd.Series(y_test), pd.Series(pred))\n",
    "    opportunity = equal_opportunity_difference(pd.Series(y_test), pd.Series(pred))\n",
    "    \n",
    "    \n",
    "    print(\"statistical parity: \" + str(parity))\n",
    "    print(\"Equality of odds: \" + str(odds))\n",
    "    print(\"Equality of opportunity: \" + str(opportunity))\n",
    "    \n",
    "    \n",
    "    return pred, mod.score(test_feats, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0b02e7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gykim/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/gykim/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/gykim/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/gykim/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/gykim/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/gykim/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistical parity: 0.41396964710184675\n",
      "Equality of odds: 0.4858518227572915\n",
      "Equality of opportunity: 0.624715693707354\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6462522851919561"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_missing_fairness = model(train, test, cat)[1]\n",
    "no_missing_fairness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3d659cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_missing(train, test, cats):\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "    \n",
    "    traincat_df = train[cats]\n",
    "    # OHE train categorical\n",
    "    train_ohe = ohe.fit_transform(traincat_df)\n",
    "    # concat non-cat train features\n",
    "    train_len = train.shape[0]\n",
    "\n",
    "    train_num_feats = np.concatenate(\n",
    "        [np.reshape(train.complainant_age_incident.values, (train_len, 1))\n",
    "        ], axis = 1\n",
    "    )\n",
    "    \n",
    "    # concatenate train OHE features with non-cat features\n",
    "    train_feats = pd.DataFrame(np.concatenate([train_ohe.todense(), train_num_feats], axis = 1))\n",
    "    train_feats['complainant_ethnicity'] = (train['complainant_ethnicity'] == \"White\").tolist()\n",
    "    train_feats['complainant_gender'] = (train['complainant_gender'] == \"Male\").tolist()\n",
    "    y_train = train.substantiated.values.astype('int')\n",
    "    \n",
    "    mod = HistGradientBoostingClassifier()\n",
    "    mod.fit(train_feats, y_train)\n",
    "    \n",
    "    testcat_df = test[cats]\n",
    "    # OHE train categorical\n",
    "    test_ohe = ohe.transform(testcat_df)\n",
    "    # concat non-cat train features\n",
    "    test_len = test.shape[0]\n",
    "\n",
    "    test_num_feats = np.concatenate(\n",
    "        [np.reshape(test.complainant_age_incident.values, (test_len, 1)),\n",
    "        ], axis = 1\n",
    "    )\n",
    "        \n",
    "    # concatenate test OHE features with non-cat features\n",
    "    test_feats = pd.DataFrame(np.concatenate([test_ohe.todense(), test_num_feats], axis = 1))\n",
    "    test_feats['complainant_ethnicity'] = (test['complainant_ethnicity'] == \"White\").tolist()\n",
    "    test_feats['complainant_gender'] = (test['complainant_gender'] == \"Male\").tolist()\n",
    "    y_test = test.substantiated.values.astype('int')\n",
    "    \n",
    "    pred = mod.predict(test_feats)\n",
    "    \n",
    "    parity = statistical_parity_difference(pd.Series(y_test), pd.Series(pred))\n",
    "    odds = average_odds_difference(pd.Series(y_test), pd.Series(pred))\n",
    "    opportunity = equal_opportunity_difference(pd.Series(y_test), pd.Series(pred))\n",
    "    \n",
    "    \n",
    "    print(\"statistical parity: \" + str(parity))\n",
    "    print(\"Equality of odds: \" + str(odds))\n",
    "    print(\"Equality of opportunity: \" + str(opportunity))\n",
    "    \n",
    "    \n",
    "    return pred, mod.score(test_feats, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "acdca1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nmar, test_nmar = train_test_split(nmar, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a5a99e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gykim/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/gykim/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/gykim/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/gykim/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/gykim/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistical parity: 0.09566685424873382\n",
      "Equality of odds: 0.1235327274008314\n",
      "Equality of opportunity: 0.19298245614035087\n"
     ]
    }
   ],
   "source": [
    "nmar_fairness = model_missing(train_nmar, test_nmar, cat)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a03e854",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
