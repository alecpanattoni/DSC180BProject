{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0306114",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcleaning\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datacleaning\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data_generation\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreparation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m model_perform\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/MissingnessFairnessAnalysis/src/preparation/model_perform.py:46\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Markdown, display\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m     47\u001b[0m tf\u001b[38;5;241m.\u001b[39mdisable_eager_execution()\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# In[ ]:\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \n\u001b[1;32m     52\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m \n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# In[3]:\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from src.cleaning import datacleaning\n",
    "from src import data_generation\n",
    "from src.preparation import model_perform\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import aif360\n",
    "from sklearn.model_selection import train_test_split\n",
    "from aif360.sklearn.metrics import statistical_parity_difference\n",
    "from aif360.sklearn.metrics import average_odds_difference\n",
    "from aif360.sklearn.metrics import equal_opportunity_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9be16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datacleaning.cleaning(os.path.join(os.path.dirname(\n",
    "    os.path.realpath('run.py')) + '/data/allegations_raw.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0836bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = sys.argv[1]\n",
    "\n",
    "if target == \"test\":\n",
    "    data = datacleaning.cleaning(os.path.join(os.path.dirname(\n",
    "        os.path.realpath('run.py')) + '/data/test.csv'))\n",
    "\n",
    "if target == \"all\":\n",
    "    data = datacleaning.cleaning(os.path.join(os.path.dirname(\n",
    "        os.path.realpath('run.py')) + '/data/allegations_raw.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f71e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069dbf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17adee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, train_size=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584b4eb3",
   "metadata": {},
   "source": [
    "## Missingness Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b9a145",
   "metadata": {},
   "source": [
    "We want the attribute with missingness to have around the same proportion of missingness for each type. This is because we don't want the amount of missingness to be a confounding factor in our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9003b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = train.copy()\n",
    "mcar = data_generation.mcar(t, 'substantiated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9551b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcar['substantiated'].isna().sum() / mcar.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9665fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcar = mcar.dropna(subset = 'substantiated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37671df",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = train.copy()\n",
    "mar = data_generation.mar(t, 'substantiated', 'complainant_ethnicity', 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d7a05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mar['substantiated'].isna().sum() / mar.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550eec64",
   "metadata": {},
   "outputs": [],
   "source": [
    "mar = mar.dropna(subset = 'substantiated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c7eac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = train.copy()\n",
    "nmar = data_generation.nmar(t, 'substantiated', 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e6f66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmar['substantiated'].isna().sum() / nmar.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e30cfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmar = nmar.dropna(subset = 'substantiated')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c14eb6",
   "metadata": {},
   "source": [
    "Now we will \"handle\" the missingness by dropping missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3aa438",
   "metadata": {},
   "source": [
    "## Applying Fairness Notions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776e6a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = [\"complainant_ethnicity\", \"complainant_age_incident\", \"allegation\", \"contact_reason\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0ad122",
   "metadata": {},
   "source": [
    "### Calculating fairnes notions for No Missingness At All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7be59a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing fairness notions for no missingness\n",
    "no_missing_fairness = []\n",
    "no_missing = model_perform.model(train, test, cat)\n",
    "no_missing_fairness.append(no_missing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7926f6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9550470b",
   "metadata": {},
   "source": [
    "### Fairness notions for NMAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdca1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nmar, test_nmar = train_test_split(nmar, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a99e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmar_fairness = []\n",
    "nmar_model = model_perform.model_missing(train_nmar, test_nmar, cat)\n",
    "nmar_fairness.append(nmar_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ee07ea",
   "metadata": {},
   "source": [
    "### Fairness notions for MCAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a03e854",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mcar, test_mcar = train_test_split(mcar, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfffff0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcar_fairness = []\n",
    "mcar_model = model_perform.model_missing(train_mcar, test_mcar, cat)\n",
    "mcar_fairness.append(mcar_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0017cc2",
   "metadata": {},
   "source": [
    "### Fairness notions for MAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae2b7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mar, test_mar = train_test_split(mar, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baeebfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "mar_fairness = []\n",
    "mar_model = model_perform.model_missing(train_mar, test_mar, cat)\n",
    "mar_fairness.append(mar_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c94992",
   "metadata": {},
   "outputs": [],
   "source": [
    "#put our fairness statistics into arrays for future usage\n",
    "acc = [no_missing_fairness[0][0],nmar_fairness[0][0],mcar_fairness[0][0],mar_fairness[0][0]]\n",
    "par= [no_missing_fairness[0][1],nmar_fairness[0][1],mcar_fairness[0][1],mar_fairness[0][1]]\n",
    "odds= [no_missing_fairness[0][2],nmar_fairness[0][2],mcar_fairness[0][2],mar_fairness[0][2]]\n",
    "opp = [no_missing_fairness[0][3],nmar_fairness[0][3],mcar_fairness[0][3],mar_fairness[0][3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4782fd68",
   "metadata": {},
   "source": [
    "## Visualizing Our Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1985f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f030e3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['No Missingess,', 'NMAR', 'MCAR', 'MAR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a714f6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 10))\n",
    "plt.title('Statistical Parities')\n",
    "plt.xlabel('Missingness Type')\n",
    "plt.ylabel('Statistical Parotities')\n",
    "plt.ylim(min(par) - 0.1, max(par) + 0.1)\n",
    "plt.plot(labels, par, marker='.', markersize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672012ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 10))\n",
    "plt.title('Equality of Odds')\n",
    "plt.xlabel('Missingness Type')\n",
    "plt.ylabel('Equality of Odds')\n",
    "plt.ylim(min(odds)-0.1,max(odds) + 0.1)\n",
    "plt.plot(labels, odds, marker='.', markersize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69974c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 10))\n",
    "plt.title('Equality of Opportunity')\n",
    "plt.xlabel('Missingness Type')\n",
    "plt.ylabel('Equality of Opportunity')\n",
    "plt.ylim(min(opp)-0.1,max(opp) + 0.1)\n",
    "plt.plot(labels, opp, marker='.', markersize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d025064",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 10))\n",
    "plt.title('Accuracies')\n",
    "plt.xlabel('Missingness Type')\n",
    "plt.ylabel('Accuracies')\n",
    "plt.ylim(min(acc)-0.1,max(acc) + 0.1)\n",
    "plt.plot(labels, acc, marker='.', markersize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcdfef0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
