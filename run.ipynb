{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22b8839a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-metal in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (0.7.1)\n",
      "Requirement already satisfied: wheel~=0.35 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorflow-metal) (0.38.4)\n",
      "Requirement already satisfied: six>=1.15.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorflow-metal) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow-metal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0306114",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alecpanattoni/Documents/MissingnessFairnessAnalysis/src/data_generation.py:86: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[column].iloc[i] = np.nan\n",
      "/Users/alecpanattoni/Documents/MissingnessFairnessAnalysis/src/data_generation.py:134: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[miss_column].iloc[i] = np.nan\n",
      "/Users/alecpanattoni/Documents/MissingnessFairnessAnalysis/src/data_generation.py:195: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[column].iloc[i] = np.nan\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "      <th>117</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>complainant_age_incident</th>\n",
       "      <th>complainant_gender</th>\n",
       "      <th>substantiated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19830</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19831</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19832</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19833</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19834</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19835 rows × 125 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0    1    2    3    4    5    6    7    8    9  ...  115  116  117  \\\n",
       "0      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "1      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "2      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "3      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "4      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "19830  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "19831  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "19832  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "19833  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "19834  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "       118  119  120  121  complainant_age_incident  complainant_gender  \\\n",
       "0      0.0  0.0  0.0  0.0                      24.0                   0   \n",
       "1      0.0  0.0  0.0  0.0                      44.0                   1   \n",
       "2      0.0  0.0  0.0  0.0                      49.0                   1   \n",
       "3      0.0  0.0  0.0  0.0                      30.0                   1   \n",
       "4      0.0  0.0  0.0  0.0                      19.0                   1   \n",
       "...    ...  ...  ...  ...                       ...                 ...   \n",
       "19830  0.0  0.0  0.0  0.0                      21.0                   1   \n",
       "19831  0.0  0.0  0.0  0.0                      34.0                   1   \n",
       "19832  0.0  0.0  0.0  0.0                      30.0                   1   \n",
       "19833  0.0  0.0  0.0  0.0                      17.0                   1   \n",
       "19834  0.0  0.0  0.0  0.0                      46.0                   1   \n",
       "\n",
       "       substantiated  \n",
       "0                  1  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  0  \n",
       "...              ...  \n",
       "19830              0  \n",
       "19831              1  \n",
       "19832              0  \n",
       "19833              0  \n",
       "19834              0  \n",
       "\n",
       "[19835 rows x 125 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-23 01:07:15.141158: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-02-23 01:07:15.141927: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1176: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-23 01:07:15.321496: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:357] MLIR V1 optimization pass is not enabled\n",
      "2023-02-23 01:07:15.331119: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-02-23 01:07:15.339960: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-23 01:07:16.021312: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-23 01:07:16.024999: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 1.695578; batch adversarial loss: 0.553747\n",
      "epoch 1; iter: 0; batch classifier loss: 0.534149; batch adversarial loss: 0.640298\n",
      "epoch 2; iter: 0; batch classifier loss: 0.563562; batch adversarial loss: 0.623199\n",
      "epoch 3; iter: 0; batch classifier loss: 0.543788; batch adversarial loss: 0.571855\n",
      "epoch 4; iter: 0; batch classifier loss: 0.546375; batch adversarial loss: 0.548551\n",
      "epoch 5; iter: 0; batch classifier loss: 0.525541; batch adversarial loss: 0.508093\n",
      "epoch 6; iter: 0; batch classifier loss: 0.483257; batch adversarial loss: 0.556190\n",
      "epoch 7; iter: 0; batch classifier loss: 0.554931; batch adversarial loss: 0.469103\n",
      "epoch 8; iter: 0; batch classifier loss: 0.613127; batch adversarial loss: 0.486429\n",
      "epoch 9; iter: 0; batch classifier loss: 0.524833; batch adversarial loss: 0.417026\n",
      "epoch 10; iter: 0; batch classifier loss: 0.474516; batch adversarial loss: 0.490171\n",
      "epoch 11; iter: 0; batch classifier loss: 0.510365; batch adversarial loss: 0.464931\n",
      "epoch 12; iter: 0; batch classifier loss: 0.493978; batch adversarial loss: 0.550031\n",
      "epoch 13; iter: 0; batch classifier loss: 0.498154; batch adversarial loss: 0.453822\n",
      "epoch 14; iter: 0; batch classifier loss: 0.557174; batch adversarial loss: 0.499672\n",
      "epoch 15; iter: 0; batch classifier loss: 0.526500; batch adversarial loss: 0.527992\n",
      "epoch 16; iter: 0; batch classifier loss: 0.569037; batch adversarial loss: 0.509018\n",
      "epoch 17; iter: 0; batch classifier loss: 0.558672; batch adversarial loss: 0.469220\n",
      "epoch 18; iter: 0; batch classifier loss: 0.602097; batch adversarial loss: 0.431823\n",
      "epoch 19; iter: 0; batch classifier loss: 0.442074; batch adversarial loss: 0.445358\n",
      "epoch 20; iter: 0; batch classifier loss: 0.520037; batch adversarial loss: 0.479922\n",
      "epoch 21; iter: 0; batch classifier loss: 0.392459; batch adversarial loss: 0.352429\n",
      "epoch 22; iter: 0; batch classifier loss: 0.527531; batch adversarial loss: 0.399858\n",
      "epoch 23; iter: 0; batch classifier loss: 0.452331; batch adversarial loss: 0.461802\n",
      "epoch 24; iter: 0; batch classifier loss: 0.471060; batch adversarial loss: 0.374648\n",
      "epoch 25; iter: 0; batch classifier loss: 0.557645; batch adversarial loss: 0.429828\n",
      "epoch 26; iter: 0; batch classifier loss: 0.490637; batch adversarial loss: 0.422798\n",
      "epoch 27; iter: 0; batch classifier loss: 0.538736; batch adversarial loss: 0.383484\n",
      "epoch 28; iter: 0; batch classifier loss: 0.506065; batch adversarial loss: 0.384964\n",
      "epoch 29; iter: 0; batch classifier loss: 0.529867; batch adversarial loss: 0.485356\n",
      "epoch 30; iter: 0; batch classifier loss: 0.503162; batch adversarial loss: 0.430650\n",
      "epoch 31; iter: 0; batch classifier loss: 0.514253; batch adversarial loss: 0.488214\n",
      "epoch 32; iter: 0; batch classifier loss: 0.500127; batch adversarial loss: 0.469808\n",
      "epoch 33; iter: 0; batch classifier loss: 0.501978; batch adversarial loss: 0.407691\n",
      "epoch 34; iter: 0; batch classifier loss: 0.488420; batch adversarial loss: 0.373108\n",
      "epoch 35; iter: 0; batch classifier loss: 0.458630; batch adversarial loss: 0.435741\n",
      "epoch 36; iter: 0; batch classifier loss: 0.471130; batch adversarial loss: 0.468144\n",
      "epoch 37; iter: 0; batch classifier loss: 0.504471; batch adversarial loss: 0.421128\n",
      "epoch 38; iter: 0; batch classifier loss: 0.494076; batch adversarial loss: 0.427417\n",
      "epoch 39; iter: 0; batch classifier loss: 0.507940; batch adversarial loss: 0.504937\n",
      "epoch 40; iter: 0; batch classifier loss: 0.519807; batch adversarial loss: 0.499109\n",
      "epoch 41; iter: 0; batch classifier loss: 0.484044; batch adversarial loss: 0.444413\n",
      "epoch 42; iter: 0; batch classifier loss: 0.470931; batch adversarial loss: 0.421451\n",
      "epoch 43; iter: 0; batch classifier loss: 0.470285; batch adversarial loss: 0.432104\n",
      "epoch 44; iter: 0; batch classifier loss: 0.461979; batch adversarial loss: 0.625021\n",
      "epoch 45; iter: 0; batch classifier loss: 0.479180; batch adversarial loss: 0.456130\n",
      "epoch 46; iter: 0; batch classifier loss: 0.495775; batch adversarial loss: 0.468490\n",
      "epoch 47; iter: 0; batch classifier loss: 0.541243; batch adversarial loss: 0.481542\n",
      "epoch 48; iter: 0; batch classifier loss: 0.449605; batch adversarial loss: 0.469722\n",
      "epoch 49; iter: 0; batch classifier loss: 0.480119; batch adversarial loss: 0.446802\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (128, 112) for Tensor debiased_classifier/Placeholder:0, which has shape (None, 124)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcleaning\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datacleaning\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data_generation\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreparation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m model_perform\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/MissingnessFairnessAnalysis/src/preparation/model_perform.py:239\u001b[0m\n\u001b[1;32m    236\u001b[0m train \u001b[38;5;241m=\u001b[39m nypd\u001b[38;5;241m.\u001b[39msample(frac\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m    237\u001b[0m test \u001b[38;5;241m=\u001b[39m nypd\u001b[38;5;241m.\u001b[39mdrop(train\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m--> 239\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcats\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;66;03m# In[26]:\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \n\u001b[1;32m    244\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    262\u001b[0m \n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# In[20]:\u001b[39;00m\n\u001b[1;32m    266\u001b[0m train, test \u001b[38;5;241m=\u001b[39m train_test_split(nypd, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/MissingnessFairnessAnalysis/src/preparation/model_perform.py:210\u001b[0m, in \u001b[0;36mmodel\u001b[0;34m(train, test, cats)\u001b[0m\n\u001b[1;32m    207\u001b[0m debiased_model\u001b[38;5;241m.\u001b[39mfit(train_bld)\n\u001b[1;32m    209\u001b[0m \u001b[38;5;66;03m# Make predictions on the test data\u001b[39;00m\n\u001b[0;32m--> 210\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mdebiased_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_bld\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlabels\n\u001b[1;32m    212\u001b[0m \u001b[38;5;66;03m# Compute accuracy and fairness metrics\u001b[39;00m\n\u001b[1;32m    213\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubstantiated\u001b[39m\u001b[38;5;124m'\u001b[39m], y_pred)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/aif360/algorithms/transformer.py:27\u001b[0m, in \u001b[0;36maddmetadata.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 27\u001b[0m     new_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(new_dataset, Dataset):\n\u001b[1;32m     29\u001b[0m         new_dataset\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;241m=\u001b[39m new_dataset\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/aif360/algorithms/inprocessing/adversarial_debiasing.py:260\u001b[0m, in \u001b[0;36mAdversarialDebiasing.predict\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    252\u001b[0m     batch_protected_attributes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(dataset\u001b[38;5;241m.\u001b[39mprotected_attributes[batch_ids][:,\n\u001b[1;32m    253\u001b[0m                                  dataset\u001b[38;5;241m.\u001b[39mprotected_attribute_names\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprotected_attribute_name)], [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    255\u001b[0m     batch_feed_dict \u001b[38;5;241m=\u001b[39m {\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures_ph: batch_features,\n\u001b[1;32m    256\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrue_labels_ph: batch_labels,\n\u001b[1;32m    257\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprotected_attributes_ph: batch_protected_attributes,\n\u001b[1;32m    258\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep_prob: \u001b[38;5;241m1.0\u001b[39m}\n\u001b[0;32m--> 260\u001b[0m     pred_labels \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpred_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_feed_dict\u001b[49m\u001b[43m)\u001b[49m[:,\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m    261\u001b[0m     samples_covered \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_features)\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# Mutated, fairer dataset with new labels\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/client/session.py:968\u001b[0m, in \u001b[0;36mBaseSession.run\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    965\u001b[0m run_metadata_ptr \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_NewBuffer() \u001b[38;5;28;01mif\u001b[39;00m run_metadata \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    967\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 968\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mrun_metadata_ptr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    970\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m run_metadata:\n\u001b[1;32m    971\u001b[0m     proto_data \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/client/session.py:1165\u001b[0m, in \u001b[0;36mBaseSession._run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1161\u001b[0m   np_val \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(subfeed_val, dtype\u001b[38;5;241m=\u001b[39msubfeed_dtype)\n\u001b[1;32m   1163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m is_tensor_handle_feed \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m   1164\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m subfeed_t\u001b[38;5;241m.\u001b[39mget_shape()\u001b[38;5;241m.\u001b[39mis_compatible_with(np_val\u001b[38;5;241m.\u001b[39mshape)):\n\u001b[0;32m-> 1165\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1166\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot feed value of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(np_val\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for Tensor \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1167\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubfeed_t\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, which has shape \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1168\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(subfeed_t\u001b[38;5;241m.\u001b[39mget_shape())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mis_feedable(subfeed_t):\n\u001b[1;32m   1170\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTensor \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubfeed_t\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m may not be fed.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (128, 112) for Tensor debiased_classifier/Placeholder:0, which has shape (None, 124)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from src.cleaning import datacleaning\n",
    "from src import data_generation\n",
    "from src.preparation import model_perform\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import aif360\n",
    "from sklearn.model_selection import train_test_split\n",
    "from aif360.sklearn.metrics import statistical_parity_difference\n",
    "from aif360.sklearn.metrics import average_odds_difference\n",
    "from aif360.sklearn.metrics import equal_opportunity_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9be16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datacleaning.cleaning(os.path.join(os.path.dirname(\n",
    "    os.path.realpath('run.py')) + '/data/allegations_raw.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0836bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = sys.argv[1]\n",
    "\n",
    "if target == \"test\":\n",
    "    data = datacleaning.cleaning(os.path.join(os.path.dirname(\n",
    "        os.path.realpath('run.py')) + '/data/test.csv'))\n",
    "\n",
    "if target == \"all\":\n",
    "    data = datacleaning.cleaning(os.path.join(os.path.dirname(\n",
    "        os.path.realpath('run.py')) + '/data/allegations_raw.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f71e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069dbf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17adee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, train_size=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584b4eb3",
   "metadata": {},
   "source": [
    "## Missingness Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b9a145",
   "metadata": {},
   "source": [
    "We want the attribute with missingness to have around the same proportion of missingness for each type. This is because we don't want the amount of missingness to be a confounding factor in our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9003b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = train.copy()\n",
    "mcar = data_generation.mcar(t, 'substantiated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9551b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcar['substantiated'].isna().sum() / mcar.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9665fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcar = mcar.dropna(subset = 'substantiated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37671df",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = train.copy()\n",
    "mar = data_generation.mar(t, 'substantiated', 'complainant_ethnicity', 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d7a05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mar['substantiated'].isna().sum() / mar.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550eec64",
   "metadata": {},
   "outputs": [],
   "source": [
    "mar = mar.dropna(subset = 'substantiated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c7eac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = train.copy()\n",
    "nmar = data_generation.nmar(t, 'substantiated', 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e6f66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmar['substantiated'].isna().sum() / nmar.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e30cfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmar = nmar.dropna(subset = 'substantiated')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c14eb6",
   "metadata": {},
   "source": [
    "Now we will \"handle\" the missingness by dropping missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3aa438",
   "metadata": {},
   "source": [
    "## Applying Fairness Notions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776e6a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = [\"complainant_ethnicity\", \"complainant_age_incident\", \"allegation\", \"contact_reason\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0ad122",
   "metadata": {},
   "source": [
    "### Calculating fairnes notions for No Missingness At All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7be59a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing fairness notions for no missingness\n",
    "no_missing_fairness = []\n",
    "no_missing = model_perform.model(train, test, cat)\n",
    "no_missing_fairness.append(no_missing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7926f6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9550470b",
   "metadata": {},
   "source": [
    "### Fairness notions for NMAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdca1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nmar, test_nmar = train_test_split(nmar, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a99e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmar_fairness = []\n",
    "nmar_model = model_perform.model_missing(train_nmar, test_nmar, cat)\n",
    "nmar_fairness.append(nmar_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ee07ea",
   "metadata": {},
   "source": [
    "### Fairness notions for MCAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a03e854",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mcar, test_mcar = train_test_split(mcar, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfffff0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcar_fairness = []\n",
    "mcar_model = model_perform.model_missing(train_mcar, test_mcar, cat)\n",
    "mcar_fairness.append(mcar_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0017cc2",
   "metadata": {},
   "source": [
    "### Fairness notions for MAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae2b7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mar, test_mar = train_test_split(mar, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baeebfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "mar_fairness = []\n",
    "mar_model = model_perform.model_missing(train_mar, test_mar, cat)\n",
    "mar_fairness.append(mar_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c94992",
   "metadata": {},
   "outputs": [],
   "source": [
    "#put our fairness statistics into arrays for future usage\n",
    "acc = [no_missing_fairness[0][0],nmar_fairness[0][0],mcar_fairness[0][0],mar_fairness[0][0]]\n",
    "par= [no_missing_fairness[0][1],nmar_fairness[0][1],mcar_fairness[0][1],mar_fairness[0][1]]\n",
    "odds= [no_missing_fairness[0][2],nmar_fairness[0][2],mcar_fairness[0][2],mar_fairness[0][2]]\n",
    "opp = [no_missing_fairness[0][3],nmar_fairness[0][3],mcar_fairness[0][3],mar_fairness[0][3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4782fd68",
   "metadata": {},
   "source": [
    "## Visualizing Our Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1985f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f030e3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['No Missingess,', 'NMAR', 'MCAR', 'MAR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a714f6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 10))\n",
    "plt.title('Statistical Parities')\n",
    "plt.xlabel('Missingness Type')\n",
    "plt.ylabel('Statistical Parotities')\n",
    "plt.ylim(min(par) - 0.1, max(par) + 0.1)\n",
    "plt.plot(labels, par, marker='.', markersize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672012ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 10))\n",
    "plt.title('Equality of Odds')\n",
    "plt.xlabel('Missingness Type')\n",
    "plt.ylabel('Equality of Odds')\n",
    "plt.ylim(min(odds)-0.1,max(odds) + 0.1)\n",
    "plt.plot(labels, odds, marker='.', markersize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69974c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 10))\n",
    "plt.title('Equality of Opportunity')\n",
    "plt.xlabel('Missingness Type')\n",
    "plt.ylabel('Equality of Opportunity')\n",
    "plt.ylim(min(opp)-0.1,max(opp) + 0.1)\n",
    "plt.plot(labels, opp, marker='.', markersize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d025064",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 10))\n",
    "plt.title('Accuracies')\n",
    "plt.xlabel('Missingness Type')\n",
    "plt.ylabel('Accuracies')\n",
    "plt.ylim(min(acc)-0.1,max(acc) + 0.1)\n",
    "plt.plot(labels, acc, marker='.', markersize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcdfef0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
